<ol>
<li><p>Both operands of the division operator are being cast to <code>double</code>s because <code>minRetryInterval_</code> is an <code>NSTimeInterval</code>, which is of <code>typedef double</code>. Perhaps, it might make more sense to cast them both to <code>NSTimeInterval</code>s instead.</p></li>
<li><p>The <code>&amp; 0x0FFFF</code> zeros out all but the right-most 16 bits of the random <code>u_int32_t</code>, i.e., <code>unsigned int</code>, generated by <code>arc4random()</code>.</p></li>
<li><p>Yes, this should work independent of the system's endianness because the denominator, <code>0x0FFFF</code>, is the largest possible 16 bit <code>double</code>, and so, the quotient will always be less than or equal to 1.</p></li>
<li><p>The most significant bit of a <a href="http://en.wikipedia.org/wiki/Double_precision_floating-point_format" rel="nofollow"><code>double</code></a> is a <a href="http://en.wikipedia.org/wiki/Sign_bit" rel="nofollow">sign bit</a>. In this case, both sign bits are 0, so we can be sure the quotient will be positive. Also, according to the specification for <code>double</code>, <code>0x0FFFF</code> is greater in magnitude than <code>0x0FFFE</code>, for example.</p></li>
</ol>